{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d0755-808c-429a-978f-35f35684dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Get flight infos\n",
    "def get_flight_info(flight_json, airport_icoa):\n",
    "# terminal\n",
    "    try: terminal = flight_json['arrival']['terminal']\n",
    "    except: terminal = None\n",
    "# aircraft\n",
    "    try: aircraft = flight_json['aircraft']['model']\n",
    "    except: aircraft = None\n",
    "\n",
    "    return {\n",
    "        'dep_airport':flight_json['departure']['airport']['name'],\n",
    "        'sched_arr_loc_time':flight_json['arrival']['scheduledTimeLocal'],\n",
    "        'terminal':terminal,\n",
    "        'status':flight_json['status'],\n",
    "        'aircraft':aircraft,\n",
    "        'icao_code':airport_icoa\n",
    "        }\n",
    "\n",
    "#Get population data \n",
    "cities = ['Berlin','Paris','Amsterdam','Barcelona','Rome','Lisbon','Prague','Vienna','Madrid', 'Stuttgart']\n",
    "def City_info(soup):\n",
    "    \n",
    "    ret_dict = {}\n",
    "    ret_dict['city'] = soup.h1.get_text()\n",
    "    \n",
    "    \n",
    "    if soup.select_one('.mergedrow:-soup-contains(\"Mayor\")>.infobox-label') != None:\n",
    "        i = soup.select_one('.mergedrow:-soup-contains(\"Mayor\")>.infobox-label')\n",
    "        mayor_name_html = i.find_next_sibling()\n",
    "        mayor_name = unicodedata.normalize('NFKD',mayor_name_html.get_text())\n",
    "        ret_dict['mayor']  = mayor_name\n",
    "    if soup.select_one('.mergedrow:-soup-contains(\"City\")>.infobox-label') != None:\n",
    "        j =  soup.select_one('.mergedrow:-soup-contains(\"City\")>.infobox-label')\n",
    "        area = j.find_next_sibling('td').get_text()\n",
    "        ret_dict['city_size'] = unicodedata.normalize('NFKD',area)\n",
    "    if soup.select_one('.mergedtoprow:-soup-contains(\"Elevation\")>.infobox-data') != None:\n",
    "        k = soup.select_one('.mergedtoprow:-soup-contains(\"Elevation\")>.infobox-data')\n",
    "        elevation_html = k.get_text()\n",
    "        ret_dict['elevation'] = unicodedata.normalize('NFKD',elevation_html)\n",
    "    if soup.select_one('.mergedtoprow:-soup-contains(\"Population\")') != None:\n",
    "        l = soup.select_one('.mergedtoprow:-soup-contains(\"Population\")')\n",
    "        c_pop = l.findNext('td').get_text()\n",
    "        ret_dict['city_population'] = c_pop\n",
    "    if soup.select_one('.infobox-label>[title^=Urban]') != None:\n",
    "        m = soup.select_one('.infobox-label>[title^=Urban]')\n",
    "        u_pop = m.findNext('td')\n",
    "        ret_dict['urban_population'] = u_pop.get_text()\n",
    "    if soup.select_one('.infobox-label>[title^=Metro]') != None:\n",
    "        n = soup.select_one('.infobox-label>[title^=Metro]')\n",
    "        m_pop = n.findNext('td')\n",
    "        ret_dict['metro_population'] = m_pop.get_text()\n",
    "    if soup.select_one('.latitude') != None:\n",
    "        o = soup.select_one('.latitude')\n",
    "        ret_dict['lat'] = o.get_text()\n",
    "    if soup.select_one('.longitude') != None:    \n",
    "        p = soup.select_one('.longitude')\n",
    "        ret_dict['long'] = p.get_text()\n",
    "        \n",
    "    return ret_dict\n",
    "    \n",
    "#Start Lambda function\n",
    "def lambda_handler(event, context):\n",
    "#Get flight information\n",
    "    airport_icoa = \"EDDS\"\n",
    "    to_local_time = \"2021-12-01T20:00\"\n",
    "    from_local_time = \"2021-12-02T08:00\"\n",
    "    flight_api_key = \"e39db7f26bmsha13057ceeef84dbp102050jsn189f13591088\"\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{airport_icoa}/{to_local_time}/{from_local_time}\"\n",
    "    querystring = {\"withLeg\":\"true\",\"withCancelled\":\"true\",\"withCodeshared\":\"true\",\"withCargo\":\"true\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"aerodatabox.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': flight_api_key\n",
    "        }\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    arrivals_airport = response.json()['arrivals']\n",
    "    arrivals_airport = pd.DataFrame([get_flight_info(flight, airport_icoa) for flight in arrivals_airport])\n",
    "#Get weather information\n",
    "    city = \"Stuttgart\"\n",
    "    country = \"DE\"\n",
    "    OWM_key = \"0c87854d706efc6d2ef016fb03918d7a\"\n",
    "    response = requests.get(f'http://api.openweathermap.org/data/2.5/forecast/?q={city},{country}&appid={OWM_key}&units=metric&lang=en')\n",
    "    forecast_api = response.json()['list']\n",
    "    weather_info = []\n",
    "#Using for loop generate and inser the weather information inside of the Pandas DataFrame \n",
    "#datetime, temperature, wind, prob_perc, rain_qty, snow = [], [], [], [], [], []\n",
    "    for forecast_3h in forecast_api: \n",
    "        weather_hour = {}\n",
    "    # datetime utc\n",
    "        weather_hour['datetime'] = forecast_3h['dt_txt']\n",
    "    # temperature \n",
    "        weather_hour['temperature'] = forecast_3h['main']['temp']\n",
    "    # wind\n",
    "        weather_hour['wind'] = forecast_3h['wind']['speed']\n",
    "    # probability precipitation \n",
    "        try: weather_hour['prob_perc'] = float(forecast_3h['pop'])\n",
    "        except: weather_hour['prob_perc'] = 0\n",
    "    # rain\n",
    "        try: weather_hour['rain_qty'] = float(forecast_3h['rain']['3h'])\n",
    "        except: weather_hour['rain_qty'] = 0\n",
    "    # wind \n",
    "        try: weather_hour['snow'] = float(forecast_3h['snow']['3h'])\n",
    "        except: weather_hour['snow'] = 0\n",
    "        weather_hour['municipality_iso_country'] = city + ',' + country\n",
    "        weather_info.append(weather_hour)\n",
    "#Creating the DataFrame for weather\n",
    "    weather_data = pd.DataFrame(weather_info)\n",
    "#Creating the Dataframe for population\n",
    "    list_of_city_info = []\n",
    "    for city in cities:\n",
    "        url = 'https://en.wikipedia.org/wiki/{}'.format(city)\n",
    "        web = requests.get(url,'html.parser')\n",
    "        soup = bs(web.content)\n",
    "        list_of_city_info.append(City_info(soup))\n",
    "    df_cities = pd.DataFrame(list_of_city_info)\n",
    "#Insert credentials from the MySQL Workbench connection \n",
    "    schema=\"test_1\"\n",
    "    host=\"wbs-project4-gans.c0gfsptlmf5s.eu-central-1.rds.amazonaws.com\"\n",
    "# wbs-project3-db.cfeeyohoevlp.eu-west-2.rds.amazonaws.com\n",
    "    user=\"admin\"\n",
    "    password=\"Akbar3171418*\"\n",
    "    port=3306\n",
    "    con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "# insert data to tables\n",
    "    df_cities.to_sql('cities', if_exists='append', con=con, index=False)\n",
    "    (weather_data\n",
    "     .assign(datetime = lambda x: pd.to_datetime(x['datetime']))\n",
    "     .to_sql('weather', if_exists='append', con=con, index=False)\n",
    "    )\n",
    "# flight arrivals\n",
    "    (arrivals_airport\n",
    "     .replace({np.nan},'unknown')\n",
    "     .assign(sched_arr_loc_time = lambda x: pd.to_datetime(x['sched_arr_loc_time']))\n",
    "     .to_sql('arrivals', if_exists='append', con=con, index=False))\n",
    "     .to_sql('arrivals2', if_exists='append', con=con, index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
